\section{Diskussion}

Durch die Ergebnisse konnte gezeigt werden, dass die hier gewählten Ansätze grundsätzlich funktionieren. Die Tafelerkennung ist relativ robust in der Lage, Tafeln zu erkennen, die bestimmte Kriterien erfüllen, und auch die Texterkennung ist grundsätzlich trotz der niedrigen Qualität des Ausgangsmaterials möglich.
%Problematik der Tafel
\subsection{Tafelerkennung}
Probleme bei der Tafeldetektion entstehen dann, wenn die Tafel nicht klar als Rechteck erkannt werden kann. Durch den doppelten, breiten Rahmen der Projekttafeln ist dieser Fall nie gegeben. In den wenigen Fällen, in denen der Rahmen teilweise durch ein Objekt verdeckt ist, bleibt der innere Rand davon unberührt und ermöglicht so die Erkennung der Schieferfläche im Kontrast zum Rahmen. Auch der umgekehrte Fall, dass ein Objekt im Hintergrund dem Tafelrahmen so ähnlich ist, dass es als Teil der gleichen Kontur erkannt wird, kann so kompensiert werden (Abbildung \ref{fig:tafelrand}).
\begin{figure}[h!]
\includegraphics[width =0.5\textwidth]{tafelrand.PNG}
\includegraphics[width =0.5\textwidth]{tafelrand2.PNG}
\caption{Ein Stein im Hintergrund wurde aufgrund der Farbe als Teil des Tafelrahmens erkannt (links) und ein Messstab überlagert den Tafelrand (rechts). Beide Tafeln wurden aufgrund des inneren Rahmens korrekt erkannt.}
\label{fig:tafelrand}
\end{figure}
Die Falsch-Negative der Grabungen des Deutschen Archäologischen Instituts sind alle auf das Verdecken von Teilen des Rahmens zurückzuführen. Ähnlich verhält es sich bei den Fotos der Ökohydrologie. Hier ist die Tafel komplett rahmenlos, was die Unterscheidung vom Hintergrund zusätzlich erschwert (Abbildung \ref{fig:tafelrand2}).
\begin{figure}[h!]
\includegraphics[width =0.5\textwidth]{tafelrand3.PNG}
\includegraphics[width =0.5\textwidth]{tafelrand4.PNG}
\caption{Helle Farbe und Lichtspiegelung erschweren die Unterscheidung vom Hintergrund (links) und Objekte überlagern den Tafelrand (rechts). Beide Tafeln wurden nicht erkannt, wie an der fehlenden grünen Umrandung zu sehen ist.}
\label{fig:tafelrand2}
\end{figure}
Um das Problem der überlagerten Umrandung zu lösen könnte der Anteil, den die Fläche der Kontur an der Fläche des umgebenden minimalen Rechtecks hat, herabgesetzt werden. Dadurch könnte natürlich auch der Anteil der Falsch-Positiven steigen. Außerdem könnten Maßnahmen wie eine Konvexe Hülle oder \textit{Contour Approximation} angewendet werden  \cite{opencvcontours}, die die Rekonstruktion eines Rechteckes zulassen, wenn Teile davon überlagert sind. Der fehlende Kontrast zum Hintergrund könnte mit dem Untersuchen weiterer Farbkanäle ausgeglichen werden. Eine Anpassung ist in jedem Falle nötig, aber auch möglich.
%Problematik der Kreide
\subsection{Texterkennung}
\label{section:diskussiontexterkennung}
Eine größere Herausforderung stellt die Schrift dar.
%Natural Scene
Die Detektion findet in einer natürlichen Umgebung statt. Normalerweise müssen Textfelder in solchen Fällen erst aufwändig gesucht werden \cite{qixiangye}, was in diesem Fall durch die Eingrenzung auf die Tafeln gelöst wird. Die übrigen Verhältnisse bleiben jedoch erhalten: Wechselnde Lichtverhältnisse und Rotationen der beschriebenen Fläche um mehrere Achsen verschlechtern die Ergebnisse \cite{xilinchen}{} \cite{tesseractoptimum}. Grenzwerte und das \verb|Hough|-Verfahren sollten hier die Umstände verbessern, was jedoch nur bedingt zum Erfolg führte. Das lässt sich daran erkennen, dass die Ergebnisse des \verb|Hough|-Verfahrens im Schnitt schlechter sind als die des \verb|Simple Crop|-Verfahrens. Ursache ist hier, dass der Tafelrand durch Abnutzungserscheinungen, seine gerundete Form und Unschärfe durch die niedrige Auflösung über keine klare Kante verfügt und daher pro Kante nicht eine, sondern oft mehrere Linien erkannt werden, die beinahe, aber nicht ganz, parallel verlaufen (Abbildung \ref{fig:lines}). Das verschiebt die erkannten Eckpunkte minimal und führt zu einer Verzerrung der Tafel bei der Projektion und somit auch der Schrift. Das Ziel einer Vereinheitlichung des Schriftbildes konnte so also nicht erreicht werden. Eine zusätzliche Erschwernis entsteht dadurch, dass, je nach Lichteinfall, ein Gitterlinienmuster auf der Tafel, das der Orientierung beim Schreiben dienen soll, sichtbar wird und die Buchstaben überlagert, was unter kontrollierten Bedingungen entweder vermieden oder zumindest leichter aus dem Bild entfernt werden könnte\footnote{Wären die Gitterlinien auf allen Tafeln zu sehen, hätten sie als Orientierung für die Entzerrung der Tafel dienen können. So sind sie jedoch als Störung und nicht als Hilfsmittel zu betrachten.}.
Der Versuch der Schärfung des Bildes durch eine Unscharfmaskierung\footnote{Bei der Unscharfmaskierung wird das Originalbild mit einer unscharfen Kopie verglichen. Überschreitet die Differenz der beiden Bilder an einem Pixel einen Grenzwert, wird an dieser Stelle das unscharfe Bild vom scharfen Bild subtrahiert. So entsteht ein Schärfungseffekt \cite{gimpsharpening}.} brachte keine Verbesserung der Ergebnisse, da dadurch das Rauschen in den Bildern verstärkt und die unerwünschten Gitterlinien betont wurden. Aus dem gleichen Grund erwies sich auch die Anwendung eines bilateralen Filters, der das Bild weichzeichnet und so das Rauschen reduziert, dabei aber scharfe Kanten bewahrt \cite{tomasi}, nicht als hilfreich.\\
%Handschrift
Generell ist Handschrift problematisch: Da sich Handschriften immer voneinander unterscheiden, müssen für eine gute Erkennung Neuronale Netzwerke auf eine Handschrift spezialisiert werden \cite{sumedhahallale}. Dazu lag in diesem Fall deutlich zu wenig Trainingsmaterial vor. Auch die Überlagerung von Buchstaben, die bei gedruckten Schriften in der Regel nicht vorkommt, erschwert die Erkennung zusätzlich. Dass unter diesen Umständen relativ gute Ergebnisse erzielt werden konnten, liegt vermutlich in der sauberen Handschrift in Druckbuchstaben, die auf den Tafeln des Testdatensatzes zu sehen ist. Theoretisch gibt es hier also Verbesserungspotential, durch die nötige Datenmenge für das Training eines Modells erscheint das jedoch nicht realistisch. Es stellt sich aber durchaus die Frage, ob ein Modell, das über große Mengen von Grabungsfotos aus mehreren Projekten trainiert wurde, nicht bessere Ergebnisse liefern könnte. Immerhin bestünde somit eine Spezialisierung auf Handschrift im allgemeinen sowie auf die Erzeugnisse von Schreibwerkzeugen wie Kreide oder Filzstift. Dieser Ansatz, auf einer breiten Datenbasis zu trainieren und für mehrere Schriften gute Ergebnisse zu erzielen, die dann automatisiert verbessert werden können (sogenannte \textit{mixed models}), statt sich auf eine einzelne Schrift zu spezialisieren, wurde von Springmann et al. für historische Druckerzeugnisse erfolgreich angewendet \cite{springmann}.\\
%Kreide
Das führt zum dritten großen Problem der Schrift: Die Kreide. Im Feld wurde die Tafel nicht immer gründlich gereinigt. Verwischte Kreidespuren um die Schrift herum sowie das ungleichmäßige Bild der Schrift selbst machen eine gängige Maßnahme -- Binarisierung vor der Texterkennung \cite{hamad}{} \cite{sumedhahallale}{} -- unmöglich\footnote{Die Binarisierung des Inputs ist Teil der Tesseract-Pipeline und wird daher ohnehin ausgeführt \cite{forsberg}. Eine vorherige, an das Dokument angepasste Binarisierung wird jedoch von der Dokumentation empfohlen. Entsprechende Versuche verschlechterten das Ergebnis jedoch deutlich.}. Teile der Buchstaben würden durch einen festen Grenzwert entfallen, im Gegenzug besteht die Gefahr großer weißer Flächen in den verwischten Arealen. Der adaptive Grenzwert dagegen, wie ihn Shah und Gokani vorschlagen \cite{jenilshah}, führt zu vielen Störungen und Artefakten im verwischten Bereich. Diese Faktoren wirken sich negativ auf die Texterkennung auf und ergänzen sich gegenseitig derart, dass eine Maßnahme gegen ein Problem ein anderes verstärkt (Abbildung \ref{fig:kreide}).
Ein ebenfalls zu Verbesserung der Texterkennung verwendetes Verfahren, die Erosion\footnote{Reduktion der Breite einer Linie.} bis hin zur Skelettisierung\footnote{Reduktion der Linien auf die Breite von einem Pixel.} \cite{hamad}{} \cite{sumedhahallale}{} der Schrift, scheiterte ebenfalls an dem durch die Kreide sehr unregelmäßigen Schriftbild.\\
\begin{figure}[h!]
\centering
\includegraphics[width =0.5\textwidth]{chalk.png}
\caption{Auf diesem Bild sind die Probleme durch die Kreide deutlich sichtbar: (1) Unterschiedliche Schriftbreiten, (2) Lücken und verwischte Bereiche bei O und T, (3) verwischte Kreide im unteren und linken Bildbereich, (4) Gitterlinien, die durch die verwischte Kreide besonders hervorgehoben werden.}
\label{fig:kreide}
\end{figure}
%Whitelist und Wörterbücher
Im Verlauf der Texterkennung hat sich vor allem die Whitelist als wirkungsvolles Werkzeug erwiesen. Je weniger Zeichen ein Datensatz enthält, desto präziser kann die Whitelist ausgestaltet werden und desto besser werden die Ergebnisse \cite[p.~107]{feldmann}. In der praktischen Durchführung der Texterkennung wurden Zeichen, die auf zwei der Tafeln vorkommen, nicht in die Whitelist aufgenommen \footnote{\glqq GIARDINO EX OSP TEUT\grqq, Garten des ehemaligen deutschen Hospitals. Die Whitelist enthielt daraus nur die Buchstaben G, O, S, T und U.}. Das hat den Hintergrund, dass die vor allem für die Sortierung der Tafeln wichtigen Informationen, also Kampagne, Datum und stratigrafische Einheit, darin ohnehin nicht enthalten waren, die Bedingungen für die Extraktion dieser Informationen aus den anderen Tafel aber deutlich schlechter geworden wären.
Komplett ohne Whitelist zu arbeiten hat sich in diesem Projekt nicht empfohlen, da eine Vielzahl von Störobjekten im Hintergrundrauschen als Sonderzeichen interpretiert wurde.
Der Einfluss des Wörterbuchs war, wie gezeigt werden konnte, insgesamt eher gering. Ein positiver Einfluss zeigte sich bei der Zeilenerkennung. Hier wirkt sich eine größere Vielfalt auf den Tafeln vor allem auf die Komplexität der Erstellung des Wörterbuchs aus.
Die Voreinstellungen von Tesseract zur \textit{Page Segmentation}, also zur Erkennung des Layouts und der Anordnung der Schrift sowie der Identifikation einzelner Textfelder, wurden übernommen, da es in einem empirischen Vergleich aller 13 verschiedenen Segmentierungsverfahren keine Abweichungen gab.\\
Die Bestimmung des besten Ergebnisses bei der Texterkennung funktionierte bei den hier verwendeten Tafeln gut, aber nicht optimal. Das ist darin erkennbar, dass der Durchschnittswert der als bestes Ergebnis betrachteten Texte höher liegt als der Gesamtdurchschnitt und oft nahe dem theoretischen Optimum liegt. Wie bereits beschrieben, liegt der in solchen Fällen verwendete Wert der \textit{confidence} nicht immer vor und kann bei Tesseract nur für die Zeilenerkennung verwendet werden, da er nur für Wörter und nicht für Buchstaben erhoben wird. Eine Vergleichbarkeit von Zeilen- und Buchstabenerkennung wäre somit weggefallen. Damit wäre auch der Mehrwert der parallelen Anwendung beider Verfahren hinfällig gewesen. Im eigentlichen Anwendungsfall, den Fotografien der Altgrabungen auf dem Kapitol, erfüllt das Kriterium also seinen Zweck. Bei der Anwendung auf die Tafeln der neueren Grabungen konnten anhand dessen keine Aussagen über die Qualität der Texterkennung getroffen werden, da immer alle Zeichen erkannt wurden und somit die Zeichenzahl keine Aussagekraft mehr hatte. Das Grunddilemma der Vergleichbarkeit der Methoden blieb hier aber bestehen, da die Buchstabenerkennung ohne Wörterbuch bereits hervorragende Ergebnisse liefern konnte, während die Zeilenerkennung die richtige Anzahl an Zeichen, aber nur selten das Zeichen selbst erkennen konnte.
Die Evaluation schließlich funktionierte wie gewünscht. Da die hier verwendeten Kennwerte die Reihenfolge der Buchstaben nicht berücksichtigen, wäre eine Ersetzung oder Ergänzung des \textit{Ratios} durch die Levenshtein-Distanz möglich. Diese wird durch die Zahl der nicht erkannten (zu ergänzenden), falsch erkannten (auszutauschenden) und fälschlicherweise erkannten (zu löschenden) Zeichen im erkannten Text ermittelt  \cite{Levenshtein_SPD66}.\\
%Alternativen diskutieren (Tafeln der Bodenkunde, Tafeln der späteren Grabung)
%Ausblick: Empfehlungen für die Zukunft
Schließlich ist zu erwähnen, dass auch Tesseract selbst austauschbar ist. Unter schwierigen Bedingungen und bei Handschriften schneidet die Engine zwar gleich gut oder besser ab als die Konkurrenz \cite{forsberg}. Es gibt jedoch eine Reihe von Engines, die speziell für das Erkennen von historischen Schriften entwickelt wurden und flexibler sind, wenn keine Wörterbücher vorliegen. Zu nennen wären hier vor allem OCRopus\footnote{https://github.com/ocropus/}, Kraken\footnote{https://github.com/mittagessen/kraken} und Calamari OCR\footnote{https://github.com/Calamari-OCR}. Das auf einzeilige, alphanumerische Codes spezialisierte SwiftOCR\footnote{https://github.com/NMAC427/SwiftOCR} könnte hier auch gute Ergebnisse erzielen, ist jedoch auf ein Betriebssystem beschränkt.
\subsection{Empfehlung}
Aus diesen Ergebnissen lassen sich klare Empfehlungen für Tafeln ableiten, die im Rahmen solcher Projekte verwendet und im Anschluss automatisiert ausgelesen werden sollen: (1) Die Tafel sollte intakt sein. (2) Sie sollte über einen breiten Rahmen verfügen. (3) Der Rahmen, die beschriftete Fläche und die Buchstaben sollten jeweils den maximalen Kontrast zueinander haben. (4) Die Buchstaben sollten gestanzt oder gedruckt sein. (5) Die Anordnung der Buchstaben sollte möglichst geordnet erfolgen, wobei Zeilenverläufe exakt eingehalten werden. (6) Die Tafeln sollten nicht durch Gegenstände verdeckt werden.